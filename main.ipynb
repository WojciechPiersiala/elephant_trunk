{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipympl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/home/wp/Studia/soft_robotics/gym/bin/python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Enable Interactive Plots\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39menable_matplotlib(args\u001b[38;5;241m.\u001b[39mgui\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args\u001b[38;5;241m.\u001b[39mgui, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39mgui)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3621\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3617\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning: Cannot change to a different GUI toolkit: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3618\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select))\n\u001b[1;32m   3619\u001b[0m         gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n\u001b[0;32m-> 3621\u001b[0m pt\u001b[38;5;241m.\u001b[39mactivate_matplotlib(backend)\n\u001b[1;32m   3622\u001b[0m configure_inline_support(\u001b[38;5;28mself\u001b[39m, backend)\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;66;03m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[39;00m\n\u001b[1;32m   3625\u001b[0m \u001b[38;5;66;03m# plot updates into account\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/pylabtools.py:368\u001b[0m, in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m--> 368\u001b[0m plt\u001b[38;5;241m.\u001b[39mswitch_backend(backend)\n\u001b[1;32m    370\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\u001b[38;5;241m.\u001b[39m_needmain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:271\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    269\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m backend_mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m    272\u001b[0m     cbook\u001b[38;5;241m.\u001b[39m_backend_module_name(newbackend))\n\u001b[1;32m    274\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m _get_required_interactive_framework(backend_mod)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'"
     ]
    }
   ],
   "source": [
    "#!/home/wp/Studia/soft_robotics/gym/bin/python\n",
    "# Enable Interactive Plots\n",
    "%matplotlib widget\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from manipulator.trunk_environment import TrunkEnv  # Import TrunkEnv\n",
    "\n",
    "\n",
    "class TrunkAgent:\n",
    "    def __init__(self, env: gym.Env, learning_rate: float, epsilon: float, epsilon_decay: float, final_epsilon: float, discount_factor: float = 0.95):\n",
    "        \"\"\"Initialize a reinforcement learning agent.\"\"\"\n",
    "        self.env = env\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.training_error = []\n",
    "\n",
    "        # Discretize the observation space\n",
    "        N_BINS = 20\n",
    "        self.obs_bins = [\n",
    "            np.linspace(-20, 20, N_BINS),  # x-effector\n",
    "            np.linspace(-30, 0, N_BINS),   # y-effector\n",
    "            np.linspace(-20, 20, N_BINS),  # x-target\n",
    "            np.linspace(-30, 0, N_BINS)    # y-target\n",
    "        ]\n",
    "\n",
    "        # Discretize the action space\n",
    "        ACTION_BINS = 10\n",
    "        self.action_bins = [\n",
    "            np.linspace(self.env.action_space.low[i], self.env.action_space.high[i], ACTION_BINS)\n",
    "            for i in range(self.env.action_space.shape[0])\n",
    "        ]\n",
    "\n",
    "        # Initialize Q-table\n",
    "        self.q_values = defaultdict(lambda: np.zeros(ACTION_BINS ** self.env.action_space.shape[0]))\n",
    "\n",
    "    def discretize_observation(self, obs):\n",
    "        \"\"\"Discretizes the continuous observation into bins.\"\"\"\n",
    "        discrete_obs = tuple(np.digitize(obs[i], self.obs_bins[i]) - 1 for i in range(len(obs)))\n",
    "        return discrete_obs\n",
    "\n",
    "    def discretize_action(self, action):\n",
    "        \"\"\"Discretizes a continuous action into bins.\"\"\"\n",
    "        discrete_action = tuple(np.digitize(action[i], self.action_bins[i]) - 1 for i in range(len(action)))\n",
    "        return discrete_action\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        \"\"\"Returns the best action or a random one based on epsilon.\"\"\"\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            obs_tuple = self.discretize_observation(obs)\n",
    "            best_action_idx = np.argmax(self.q_values[obs_tuple])\n",
    "\n",
    "            # Map back to continuous action space\n",
    "            best_action = np.array([\n",
    "                self.action_bins[i][best_action_idx % len(self.action_bins[i])]\n",
    "                for i in range(len(self.action_bins))\n",
    "            ])\n",
    "            return best_action\n",
    "\n",
    "    def update(self, obs, action, reward, terminated, next_obs):\n",
    "        \"\"\"Updates a Q-value of an action.\"\"\"\n",
    "        tp_obs = self.discretize_observation(obs)\n",
    "        tp_action = self.discretize_action(action)\n",
    "        action_idx = np.ravel_multi_index(tp_action, [len(b) for b in self.action_bins])\n",
    "\n",
    "        tp_next_obs = self.discretize_observation(next_obs)\n",
    "        future_q_value = (not terminated) * np.max(self.q_values[tp_next_obs])\n",
    "        temporal_difference = reward + self.discount_factor * future_q_value - self.q_values[tp_obs][action_idx]\n",
    "        self.q_values[tp_obs][action_idx] += self.lr * temporal_difference\n",
    "        self.training_error.append(float(temporal_difference))\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon - self.epsilon_decay, self.final_epsilon)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "n_episodes = 5\n",
    "start_epsilon = 1.0\n",
    "final_epsilon = 0.05\n",
    "epsilon_decay = start_epsilon / (n_episodes / 2)\n",
    "\n",
    "# Path to the folder\n",
    "folder_path = \"./trunk-agent\"\n",
    "\n",
    "# Clear the folder if it exists\n",
    "if os.path.exists(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove files\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directories\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}: {e}\")\n",
    "else:\n",
    "    os.makedirs(folder_path)  # Create folder if it doesn't exist\n",
    "\n",
    "# Environment setup\n",
    "env = gym.make(\"TrunkManipulator-v0\", render_mode=\"rgb_array\", max_steps=100)\n",
    "env = gym.wrappers.RecordVideo(env, video_folder=\"trunk-agent\", name_prefix=\"eval\", episode_trigger=lambda x: x == n_episodes or x == 1)\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env=env)\n",
    "agent = TrunkAgent(env=env, learning_rate=learning_rate, epsilon=start_epsilon, epsilon_decay=epsilon_decay, final_epsilon=final_epsilon)\n",
    "\n",
    "# Training loop\n",
    "episode_td_errors = []\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    episode_td_error = []\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        agent.update(action=action, obs=obs, next_obs=next_obs, reward=reward, terminated=terminated)\n",
    "        obs = next_obs\n",
    "        done = terminated or truncated\n",
    "        episode_td_error.append(agent.training_error[-1])\n",
    "    episode_td_errors.append(np.mean(episode_td_error))\n",
    "    agent.decay_epsilon()\n",
    "\n",
    "# Plotting the training error\n",
    "\n",
    "rolling_mean = np.convolve(episode_td_errors, np.ones(1) / 1, mode='valid')\n",
    "fig, ax = plt.subplots(3,1,figsize=(10, 12))\n",
    "ax[0].plot(rolling_mean)\n",
    "ax[0].set_title(\"Training Error\")\n",
    "ax[0].set_xlabel(\"Episode\")\n",
    "ax[0].set_ylabel(\"Mean Temporal Difference\")\n",
    "\n",
    "ax[1].plot(env.return_queue)\n",
    "ax[1].set_title(\"Episode Rewards\")\n",
    "ax[1].set_xlabel(\"Episode\")\n",
    "ax[1].set_ylabel(\"Reward\")\n",
    "\n",
    "ax[2].plot(env.length_queue)\n",
    "ax[2].set_title(\"Episode Lengths\")\n",
    "ax[2].set_xlabel(\"Episode\")\n",
    "ax[2].set_ylabel(\"Length\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluate the agent\n",
    "total_rewards = []\n",
    "for _ in range(100):  # Evaluate for 100 episodes\n",
    "    obs, info = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        done = terminated or truncated\n",
    "    total_rewards.append(episode_reward)\n",
    "\n",
    "print(f\"Average reward over 100 evaluation episodes: {np.mean(total_rewards)}\")\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "obs, info = env.reset()\n",
    "episode_over = False\n",
    "while not episode_over:\n",
    "    action = env.action_space.sample()  # replace with actual agent\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    episode_over = terminated or truncated\n",
    "\n",
    "video_path1 = 'trunk-agent/eval-episode-' + str(n_episodes) + '.mp4'\n",
    "video_path2 = 'trunk-agent/eval-episode-' + str(1) + '.mp4'\n",
    "\n",
    "# Embed both videos in a single HTML block\n",
    "HTML(f\"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <video width=\"640\" height=\"480\" controls autoplay loop muted>\n",
    "      <source src=\"{video_path2}\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "    <p>First Episode</p>\n",
    "    <video width=\"640\" height=\"480\" controls autoplay loop muted>\n",
    "      <source src=\"{video_path1}\" type=\"video/mp4\">\n",
    "      Your browser does not support the video tag.\n",
    "    </video>\n",
    "    <p>Last episode</p>\n",
    "</div>\n",
    "\"\"\")\n",
    "\n",
    "# Close the environment\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"hello\")\n",
    "2+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
